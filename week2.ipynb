{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from catboost import CatBoostRegressor,Pool\n",
    "import matplotlib.patches as patch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import NuSVR\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import norm\n",
    "from scipy import linalg\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "import lightgbm as lgb\n",
    "#import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import graphviz\n",
    "import warnings\n",
    "import random\n",
    "import eli5\n",
    "import shap  # package used to calculate Shap values\n",
    "import time\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import hann\n",
    "from scipy.signal import convolve\n",
    "from scipy import stats\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading csv files...\n",
      "Train: rows:629145480 columns:2\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Reading csv files...\")\n",
    "train = pd.read_csv('./train.csv' , dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32})\n",
    "print(\"Train: rows:{} columns:{}\".format(train.shape[0], train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4194, 1)\n",
      "Reading ends.\n"
     ]
    }
   ],
   "source": [
    "rows = 150_000\n",
    "segments = int(np.floor(train.shape[0] / rows)) # 4194\n",
    "\n",
    "X_train = pd.DataFrame(index=range(segments), dtype=np.float64) # 使用对应的特征\n",
    "y_train = pd.DataFrame(index=range(segments), dtype=np.float64,\n",
    "                       columns=['time_to_failure'])\n",
    "submission = pd.read_csv('./sample_submission.csv', index_col='seg_id')\n",
    "\n",
    "X_train =pd.read_csv('./data/4194samples/X_train_138features_filtered.csv',index_col=0)\n",
    "X_test = pd.read_csv('./data/4194samples/X_test_138features_filtered.csv',index_col=0)\n",
    "\n",
    "#y_train\n",
    "\n",
    "scale = 1  # test:使滑动窗口缩小10倍\n",
    "for segment in range(segments):\n",
    "    # y_train and X_train\n",
    "    #     if segment * rows / scale + rows > train.shape[0]:\n",
    "    #         break\n",
    "    seg = train.iloc[int(segment * rows / scale): int(segment * rows / scale + rows)]\n",
    "    x = pd.Series(seg['acoustic_data'].values)\n",
    "    y = seg['time_to_failure'].values[-1]\n",
    "    y_train.loc[segment, 'time_to_failure'] = y\n",
    "#print(X_train.head())\n",
    "#print(X_test.head())\n",
    "print(y_train.shape)\n",
    "#print(\"submission has: rows:{} cols:{}\".format(submission.shape[0], submission.shape[1]))\n",
    "print(\"Reading ends.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FillNA and standardScalar...\n",
      "FillNA and standardScalar ends.\n"
     ]
    }
   ],
   "source": [
    "# 正则化\n",
    "print(\"FillNA and standardScalar...\")\n",
    "means_dict = {}\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].isnull().any():\n",
    "        print(col)\n",
    "        mean_value = X_train.loc[X_train[col] != -np.inf, col].mean()\n",
    "        X_train.loc[X_train[col] == -np.inf, col] = mean_value\n",
    "        X_train[col] = X_train[col].fillna(mean_value)\n",
    "        means_dict[col] = mean_value\n",
    "\n",
    "for col in X_test.columns:\n",
    "    if X_test[col].isnull().any():\n",
    "        X_test.loc[X_test[col] == -np.inf, col] = means_dict[col]\n",
    "        X_test[col] = X_test[col].fillna(means_dict[col])\n",
    "\n",
    "X = X_train.copy()\n",
    "y = y_train.copy()\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "print(\"FillNA and standardScalar ends.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation\n",
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=11)\n",
    "X=X_train_scaled\n",
    "X_test=X_test_scaled\n",
    "y=y_train\n",
    "oof = np.zeros(len(X))\n",
    "prediction = np.zeros(len(X_test))\n",
    "scores = []\n",
    "feature_importance = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "{'max_depth': 2, 'min_samples_leaf': 44, 'min_samples_split': 5}\n",
      "0.45945204075560425\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "print('start')\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_test1 = {'n_estimators':range(100,1000,10)}\n",
    "gsearch1 = GridSearchCV(estimator = RandomForestRegressor(), param_grid = param_test1, scoring=None,cv=5)\n",
    "gsearch1.fit(X,y)\n",
    "GridSearchCV(cv=5, error_score='raise',estimator=RandomForestRegressor(bootstrap=True,criterion='mae',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
    "            verbose=0, warm_start=False),\n",
    "       fit_params={}, iid=True, n_jobs=1,\n",
    "       param_grid={'n_estimators': range(10, 71, 10)},\n",
    "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
    "       scoring='none', verbose=0)\n",
    "\n",
    "print(gsearch1.best_params_)\n",
    "print(gsearch1.best_score_)\n",
    "print('end')\n",
    "\n",
    "print('start')\n",
    "param_test4 = {'max_depth':range(1,5), 'min_samples_split':range(2,10),'min_samples_leaf':range(40,60,2)}\n",
    "gsearch4 = GridSearchCV(estimator = RandomForestRegressor(n_estimators=29), param_grid = param_test4, scoring=None,cv=5)\n",
    "gsearch4.fit(X,y)\n",
    "print(gsearch4.best_params_)\n",
    "print(gsearch4.best_score_)\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "2.083057608299071\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "#refit\n",
    "print('start')\n",
    "scores = []\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "    # print('Fold', fold_n, 'started at', time.ctime())\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train1, y_valid1 = y.iloc[train_index], y.iloc[valid_index]\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=29,bootstrap=True, criterion='mae',\n",
    "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=44,\n",
    "            min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
    "            n_jobs=1, oob_score=True, random_state=10,\n",
    "            verbose=0, warm_start=False)\n",
    "    model.fit(X_train, y_train1)\n",
    "    y_pred_valid = model.predict(X_valid).reshape(-1, )\n",
    "    score = mean_absolute_error(y_valid1, y_pred_valid)\n",
    "    y_pred = model.predict(X_test).reshape(-1, )\n",
    "    scores.append(score)\n",
    "\n",
    "a = 0\n",
    "for s in scores:\n",
    "    a+=s\n",
    "print(a/5)\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "2.170430039927173\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "# 不调参数的MAE\n",
    "print('start')\n",
    "scores = []\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "    # print('Fold', fold_n, 'started at', time.ctime())\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train1, y_valid1 = y.iloc[train_index], y.iloc[valid_index]\n",
    "    \n",
    "    model = RandomForestRegressor(random_state=10)\n",
    "    model.fit(X_train, y_train1)\n",
    "    y_pred_valid = model.predict(X_valid).reshape(-1, )\n",
    "    score = mean_absolute_error(y_valid1, y_pred_valid)\n",
    "    y_pred = model.predict(X_test).reshape(-1, )\n",
    "    scores.append(score)\n",
    "\n",
    "a = 0\n",
    "for s in scores:\n",
    "    a+=s\n",
    "print(a/5)\n",
    "print('end')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
